# üìå Proyecto E-commerce Analytics (Batch + Streaming)

## 1. üöÄ Descripci√≥n del Proyecto
Este proyecto implementa una **arquitectura moderna de Analytics para E-commerce**, integrando datos hist√≥ricos (batch) y datos en tiempo real (streaming).  

El objetivo es **crear dashboards en Looker Studio** que permitan analizar m√©tricas clave del negocio:
- Ingresos (*Revenue*).  
- √ìrdenes totales y detalle por producto.  
- Clientes √∫nicos y su distribuci√≥n geogr√°fica.  
- Ticket promedio (*Average Order Value - AOV*).  
- Comparativa entre batch (hist√≥rico) y streaming (tiempo real).  

---

## 2. üõ†Ô∏è Servicios de Google Cloud utilizados
| Servicio | Uso en el Proyecto |
|----------|--------------------|
| ![Cloud Storage](./imagenes/cloud_storage.png) | Almacenamiento de los CSV batch y los scripts Python. |
| ![BigQuery](./imagenes/bigquery.png) | Data Warehouse para datos hist√≥ricos, vistas anal√≠ticas y uni√≥n batch + streaming. |
| ![Pub/Sub](./imagenes/pubsub.png) | Ingesta de eventos en tiempo real (√≥rdenes simuladas). |
| ![Dataflow](./imagenes/dataflow.png) | Pipeline de streaming que procesa los eventos y los inserta en BigQuery. |
| ![Python](./imagenes/python.png) | Scripts de simulaci√≥n (`publisher.py`) y pipeline. |
| Looker Studio | Dashboards interactivos para an√°lisis. |

---

## 3. üóÇÔ∏è Modelo Entidad-Relaci√≥n (ERD)

### Tablas principales
- **Customers**
  - `customer_id (PK)`
  - `name`
  - `country`
  - `signup_date`

- **Orders**
  - `order_id (PK)`
  - `customer_id (FK)`
  - `order_date`

- **OrderItems**
  - `order_id (FK)`
  - `product_id (FK)`
  - `qty`
  - `unit_price`

- **Products**
  - `product_id (PK)`
  - `category`
  - `price`

### Relaciones
- **Customers (1) ‚Üí (N) Orders**  
- **Orders (1) ‚Üí (N) OrderItems**  
- **Products (1) ‚Üí (N) OrderItems**  

üìå **OrderItems es la tabla puente**: conecta √≥rdenes con productos y permite calcular m√©tricas como revenue.  

![Modelo ER](./imagenes/modelo_er.png)  

---

## 4. üìÇ Paso a Paso del Proyecto

### üîπ 1. Ingesta en Cloud Storage
Se cre√≥ el bucket **`bucket-ecommerce-octavio`** con:
- Carpeta `/datasets` ‚Üí CSV hist√≥ricos (customers, orders, order_items, products).  
- Carpeta `/pipelines` ‚Üí scripts Python:  
  - **publisher.py** ‚Üí publica eventos simulados en Pub/Sub.  

```python
import json, time, uuid, random
from google.cloud import pubsub_v1

publisher = pubsub_v1.PublisherClient()
topic_path = "projects/data-ecommerce-demo/topics/order_events"

while True:
    event = {
        "event_id": str(uuid.uuid4()),
        "order_id": f"O{random.randint(1000,9999)}",
        "customer_id": f"C{random.randint(1,100)}",
        "product_id": f"P{random.randint(1,50)}",
        "qty": random.randint(1,5),
        "unit_price": round(random.uniform(10,500),2),
        "event_ts": str(time.time())
    }
    publisher.publish(topic_path, json.dumps(event).encode("utf-8"))
    print("Published:", event)
    time.sleep(2)

```
### üîπ 2. Carga de datos en BigQuery
Se cre√≥ el dataset data_ecommerce_demo dentro del proyecto data-ecommerce-demo.
Se cargaron las tablas batch desde CSV:

- customers
- orders
- order_items
- products

Ejemplo de consultas exploratorias (batch):

```python
  -- Cantidad de clientes por pa√≠s
  SELECT country, COUNT(*) AS total_clientes
  FROM `data-ecommerce-demo.data_ecommerce_demo.customers`
  GROUP BY country
  ORDER BY total_clientes DESC;

  -- Clientes por a√±o de registro
  SELECT 
    EXTRACT(YEAR FROM signup_date) AS anio_registro,
    COUNT(*) AS total_clientes
  FROM `data-ecommerce-demo.data_ecommerce_demo.customers`
  GROUP BY anio_registro
  ORDER BY anio_registro;

```
